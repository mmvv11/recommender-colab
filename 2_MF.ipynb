{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmvv11/recommender-colab/blob/main/2_MF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119ab203",
      "metadata": {
        "id": "119ab203"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4331e385",
      "metadata": {
        "id": "4331e385"
      },
      "source": [
        "하이퍼파라미터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ed21e0",
      "metadata": {
        "id": "27ed21e0"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\" # 디바이스\n",
        "n_neg=4 # 네거티브 샘플링 갯수\n",
        "data_path = \"./ml-100k_splited.pkl\" # 데이터셋 경로\n",
        "batch_size = 1024 # 훈련 데이터 배치 사이즈\n",
        "emb_size = 8 # MF 임베딩 크기\n",
        "lr = 1e-3\n",
        "top_k = 20\n",
        "n_epoch=10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f22c43b",
      "metadata": {
        "id": "4f22c43b"
      },
      "source": [
        "## 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03ccd4f9",
      "metadata": {
        "id": "03ccd4f9"
      },
      "outputs": [],
      "source": [
        "with open(data_path, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "train, val, test, all_items, user2id, id2user, item2id, id2item = data.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db750558",
      "metadata": {
        "id": "db750558"
      },
      "outputs": [],
      "source": [
        "class MLDataset(Dataset):\n",
        "    def __init__(self, df, all_items, n_neg=4):\n",
        "        super().__init__()\n",
        "        self.n_neg=n_neg\n",
        "        self.users, self.items, self.labels = self.get_data(df, all_items)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.labels[idx]\n",
        "\n",
        "    def get_data(self, df, all_items):\n",
        "        users, items, labels = [], [], []\n",
        "        user_item_set = set(zip(df['user'], df['item']))\n",
        "        for u, i in user_item_set:\n",
        "            users.append(u)\n",
        "            items.append(i)\n",
        "            labels.append(1)\n",
        "            for _ in range(self.n_neg):\n",
        "                neg_item = np.random.choice(all_items)\n",
        "                while (u, neg_item) in user_item_set:\n",
        "                    neg_item = np.random.choice(all_items)\n",
        "                users.append(u)\n",
        "                items.append(neg_item)\n",
        "                labels.append(0)\n",
        "        return torch.tensor(users).to(device), torch.tensor(items).to(device), torch.tensor(labels, dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5975a7a",
      "metadata": {
        "id": "c5975a7a"
      },
      "outputs": [],
      "source": [
        "train_dataset = MLDataset(train, all_items, )\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65491bb2",
      "metadata": {
        "id": "65491bb2"
      },
      "outputs": [],
      "source": [
        "user_consumed = train.groupby(\"user\")['item'].apply(list).to_dict()\n",
        "val_true = val.groupby(\"user\")['item'].apply(list).to_dict()\n",
        "test_true = test.groupby(\"user\")['item'].apply(list).to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f4f89d1",
      "metadata": {
        "id": "6f4f89d1"
      },
      "source": [
        "# MF 모델링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8980a96",
      "metadata": {
        "id": "f8980a96"
      },
      "outputs": [],
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, n_users, n_items, emb_size):\n",
        "        super(MF, self).__init__()\n",
        "        self.emb_user = nn.Embedding(n_users, emb_size)\n",
        "        self.emb_item = nn.Embedding(n_items, emb_size)\n",
        "        self._init_weight()\n",
        "\n",
        "    def _init_weight(self):\n",
        "        nn.init.xavier_uniform_(self.emb_user.weight)\n",
        "        nn.init.xavier_uniform_(self.emb_item.weight)\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        emb_user = self.emb_user(user)\n",
        "        emb_item = self.emb_item(item)\n",
        "        return (emb_user*emb_item).sum(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442f12b2",
      "metadata": {
        "id": "442f12b2"
      },
      "source": [
        "모델, 손실 함수, 옵티마이저 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1935f00a",
      "metadata": {
        "id": "1935f00a"
      },
      "outputs": [],
      "source": [
        "n_users, n_items = len(user2id), len(item2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc392a1",
      "metadata": {
        "id": "8dc392a1"
      },
      "outputs": [],
      "source": [
        "model = MF(n_users, n_items, emb_size)\n",
        "model.to(device)\n",
        "\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e024b9",
      "metadata": {
        "id": "41e024b9"
      },
      "source": [
        "메트릭\n",
        "* precision\n",
        "* recall\n",
        "* nDCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b61a75",
      "metadata": {
        "id": "e1b61a75"
      },
      "outputs": [],
      "source": [
        "def get_precision(pred, true, k=20):\n",
        "    intersection = set(pred).intersection(set(true))\n",
        "    return len(intersection)/ k\n",
        "\n",
        "def get_recall(pred, true, k=20):\n",
        "    intersection = set(pred).intersection(set(true))\n",
        "    return len(intersection)/len(true)\n",
        "\n",
        "def get_nDCG(pred, true, k=20):\n",
        "    intersection, _, idx_in_pred = np.intersect1d(true, pred, assume_unique=True, return_indices=True)\n",
        "    if intersection.size == 0:\n",
        "        return 0\n",
        "    rank_list = np.zeros(k, np.float32)\n",
        "    rank_list[idx_in_pred] = 1\n",
        "    ideal_list = np.sort(rank_list)[::-1]\n",
        "    dcg = np.sum(rank_list/np.log2(np.arange(2, k+2)))\n",
        "    idcg = np.sum(ideal_list /np.log2(np.arange(2, k+2)))\n",
        "    return dcg/idcg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35389cb5",
      "metadata": {
        "id": "35389cb5"
      },
      "source": [
        "train process 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97e5dc7",
      "metadata": {
        "id": "c97e5dc7",
        "outputId": "c29d9bed-98b7-4990-8ba3-69ba9e8d99cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:09<00:00, 42.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, total_loss: 266.2305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 535.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1545\n",
            "precision:0.0800\n",
            "ndcg:0.3325\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 64.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2, total_loss: 190.3934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 584.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1597\n",
            "precision:0.0822\n",
            "ndcg:0.3431\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:07<00:00, 55.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3, total_loss: 151.4196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 590.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1625\n",
            "precision:0.0824\n",
            "ndcg:0.3454\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 57.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 4, total_loss: 144.8143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 596.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1695\n",
            "precision:0.0836\n",
            "ndcg:0.3482\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 58.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5, total_loss: 142.6620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 550.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1696\n",
            "precision:0.0843\n",
            "ndcg:0.3486\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:07<00:00, 55.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 6, total_loss: 141.5514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 568.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1730\n",
            "precision:0.0840\n",
            "ndcg:0.3491\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:07<00:00, 54.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 7, total_loss: 140.8562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 596.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1727\n",
            "precision:0.0846\n",
            "ndcg:0.3487\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:05<00:00, 65.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 8, total_loss: 140.3388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 488.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1743\n",
            "precision:0.0843\n",
            "ndcg:0.3517\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:07<00:00, 55.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 9, total_loss: 139.8463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 592.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1745\n",
            "precision:0.0850\n",
            "ndcg:0.3516\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 55.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, total_loss: 139.2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 587.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.1783\n",
            "precision:0.0865\n",
            "ndcg:0.3569\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 943/943 [00:01<00:00, 585.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "recall:0.1686\n",
            "precision:0.0817\n",
            "ndcg:0.3438\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epoch+1):\n",
        "    model.train()\n",
        "    total_loss= 0\n",
        "    for i, batch_data in enumerate(tqdm(train_loader, desc=\"train\")):\n",
        "        users, items, labels = batch_data\n",
        "        pred = model(users, items)\n",
        "        loss = loss_function(pred, labels)\n",
        "        total_loss+=loss\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    total_loss = total_loss.cpu().detach().numpy()\n",
        "    print(f\"epoch: {epoch}, total_loss: {np.mean(total_loss):.4f}\")\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    recall = np.array([])\n",
        "    precision = np.array([])\n",
        "    ndcg = np.array([])\n",
        "    for u, true in tqdm(val_true.items(), desc=\"eval\"):\n",
        "        # 유저별 소비하지 않은 아이템\n",
        "        unconsumed_items = list(set(all_items)-set(user_consumed[u]))\n",
        "        unconsumed_items = torch.tensor(unconsumed_items).to(device)\n",
        "        uu = torch.tensor([u]*len(unconsumed_items)).to(device)\n",
        "\n",
        "        # 추론\n",
        "        pred = model(uu, unconsumed_items)\n",
        "        _, pred_idx = torch.topk(pred, k=top_k)\n",
        "        top_k_items = unconsumed_items[pred_idx].tolist()\n",
        "\n",
        "        # 메트릭\n",
        "        recall=np.append(recall, get_recall(top_k_items, true))\n",
        "        precision=np.append(precision, get_precision(top_k_items, true))\n",
        "        ndcg=np.append(ndcg, get_nDCG(top_k_items, true))\n",
        "    print(f\"recall:{np.mean(recall):.4f}\\nprecision:{np.mean(precision):.4f}\\nndcg:{np.mean(ndcg):.4f}\\n\\n\")\n",
        "\n",
        "# validation\n",
        "model.eval()\n",
        "recall = np.array([])\n",
        "precision = np.array([])\n",
        "ndcg = np.array([])\n",
        "for u, true in tqdm(test_true.items(), desc=\"test\"):\n",
        "    # 유저별 소비하지 않은 아이템\n",
        "    unconsumed_items = list(set(all_items)-set(user_consumed[u]))\n",
        "    unconsumed_items = torch.tensor(unconsumed_items).to(device)\n",
        "    uu = torch.tensor([u]*len(unconsumed_items)).to(device)\n",
        "\n",
        "    # 추론\n",
        "    pred = model(uu, unconsumed_items)\n",
        "    _, pred_idx = torch.topk(pred, k=top_k)\n",
        "    top_k_items = unconsumed_items[pred_idx].tolist()\n",
        "\n",
        "    # 메트릭\n",
        "    recall=np.append(recall, get_recall(top_k_items, true))\n",
        "    precision=np.append(precision, get_precision(top_k_items, true))\n",
        "    ndcg=np.append(ndcg, get_nDCG(top_k_items, true))\n",
        "print(f\"\\nrecall:{np.mean(recall):.4f}\\nprecision:{np.mean(precision):.4f}\\nndcg:{np.mean(ndcg):.4f}\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}